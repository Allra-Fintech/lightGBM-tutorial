{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d22c6ae9",
   "metadata": {},
   "source": [
    "# LightGBM Ads Tutorial\n",
    "\n",
    "End-to-end tutorial using synthetic keyword-ads performance data.\n",
    "\n",
    "**Models covered:**\n",
    "1. CTR prediction (regression)\n",
    "2. Conversion prediction (binary classification)\n",
    "3. Keyword ranking function (score-based)\n",
    "4. Learning-to-Rank with LambdaMART (group-split version)\n",
    "5. Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df58ec9",
   "metadata": {},
   "source": [
    "## 0) Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27814e01",
   "metadata": {},
   "source": [
    "## 1) Create synthetic ads dataset\n",
    "\n",
    "Each row represents one `(given_word, keyword)` pair with features:\n",
    "- `similarity` – cosine-like similarity between the two words\n",
    "- `competition`, `impressions`, `clicks`, `cpc`, `cost`, `device`, `hour`\n",
    "\n",
    "Targets:\n",
    "- `ctr` – click-through rate (regression)\n",
    "- `has_conversion` – did it convert at least once? (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63d9876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "from src.dataset import make_ads_dataset\n\ndf = make_ads_dataset(n=100_000)\nprint(f\"Dataset shape: {df.shape}\")\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988b4c1",
   "metadata": {},
   "outputs": [],
   "source": "df.describe()"
  },
  {
   "cell_type": "markdown",
   "id": "21903c20",
   "metadata": {},
   "source": [
    "## 2) Prepare features\n",
    "\n",
    "LightGBM handles categorical features natively when they are `pandas.Categorical` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16f0637",
   "metadata": {},
   "outputs": [],
   "source": "from src.models import prepare_features\n\nX_train, X_test, y_ctr_train, y_ctr_test, y_conv_train, y_conv_test = prepare_features(df)\n\nprint(f\"Train: {X_train.shape}  |  Test: {X_test.shape}\")\nprint(f\"Conversion rate (train): {y_conv_train.mean():.3f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "9bde0599",
   "metadata": {},
   "source": [
    "## 3) Model A — CTR prediction (regression)\n",
    "\n",
    "CTR is continuous and bounded in (0, 1). We weight each sample by `impressions` so high-volume rows have more influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ef3b7",
   "metadata": {},
   "outputs": [],
   "source": "from src.models import train_ctr_model\n\nreg = train_ctr_model(X_train, X_test, y_ctr_train, y_ctr_test)"
  },
  {
   "cell_type": "markdown",
   "id": "344cfe2d",
   "metadata": {},
   "source": [
    "## 4) Model B — Conversion prediction (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe96b7e",
   "metadata": {},
   "outputs": [],
   "source": "from src.models import train_conversion_model\n\nclf = train_conversion_model(X_train, X_test, y_conv_train, y_conv_test)"
  },
  {
   "cell_type": "markdown",
   "id": "15e4502d",
   "metadata": {},
   "source": [
    "## 5) Rank keywords for a given word\n",
    "\n",
    "For a new `given_word`, score a list of candidate keywords using:\n",
    "- `pred_ctr` from the regression model\n",
    "- `pred_conv_prob` from the classifier\n",
    "- `score = pred_ctr × pred_conv_prob` (customize to ROAS, profit, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926eba49",
   "metadata": {},
   "outputs": [],
   "source": "from src.ranking import rank_keywords_for_given\n\ncandidates = [\"white sneakers\", \"running shoes\", \"hiking boots\", \"leather wallet\",\n              \"laptop bag\", \"wireless earbuds\", \"gaming mouse\", \"yoga mat\"]\n\nbase = {\n    \"similarity\":  0.7,\n    \"competition\": 0.6,\n    \"impressions\": 5000,\n    \"clicks\":      0,\n    \"cpc\":         2.0,\n    \"cost\":        0.0,\n    \"device\":      \"mobile\",\n    \"hour\":        21,\n}\n\nranked = rank_keywords_for_given(\"sneakers\", candidates, base, reg, clf)\nranked"
  },
  {
   "cell_type": "markdown",
   "id": "3e32e47d",
   "metadata": {},
   "source": [
    "## 6) Learning-to-Rank with LambdaMART\n",
    "\n",
    "A proper LambdaMART setup requires:\n",
    "1. **Group-based train/test split** — keep all rows for a `given_word` in the same split.\n",
    "2. **Group sizes array** — number of candidate keywords per query, in order.\n",
    "3. **Relevance labels** — here we use `ctr`; in production use ROAS or conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8cb4b",
   "metadata": {},
   "outputs": [],
   "source": "from src.models import train_ranker\n\nranker, test_words = train_ranker(df)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f3211",
   "metadata": {},
   "outputs": [],
   "source": "# Inspect ranker scores for one test given_word\nfrom src.models import FEATURE_COLS, CAT_COLS\n\nsample_word = list(test_words)[0]\ndf_sample   = df[df[\"given_word\"] == sample_word].copy()\n\nXs = df_sample[FEATURE_COLS].copy()\nfor c in CAT_COLS:\n    Xs[c] = Xs[c].astype(\"category\")\n\ndf_sample[\"ranker_score\"] = ranker.predict(Xs)\ndf_sample[[\"given_word\", \"keyword\", \"ctr\", \"ranker_score\"]] \\\n    .sort_values(\"ranker_score\", ascending=False) \\\n    .head(10) \\\n    .reset_index(drop=True)"
  },
  {
   "cell_type": "markdown",
   "id": "6ee7c66d",
   "metadata": {},
   "source": [
    "## 7) Feature importance\n",
    "\n",
    "Using **gain** (total reduction in loss attributed to each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025469cc",
   "metadata": {},
   "outputs": [],
   "source": "from src.models import feature_importance\n\nfi_reg    = feature_importance(reg,    \"CTR Regression\")\nfi_clf    = feature_importance(clf,    \"Conversion Classifier\")\nfi_ranker = feature_importance(ranker, \"LambdaMART Ranker\")"
  },
  {
   "cell_type": "markdown",
   "id": "4270d690",
   "metadata": {},
   "source": [
    "## Quick-reference: choosing the right setup\n",
    "\n",
    "| Success metric | Target variable | LightGBM objective | Eval metric |\n",
    "|---|---|---|---|\n",
    "| CTR | `ctr` (float) | `regression` | RMSE / MAE |\n",
    "| Conversion | `has_conversion` (0/1) | `binary` | AUC / PR-AUC |\n",
    "| ROAS / Profit | continuous value | `regression` or `tweedie` | RMSE |\n",
    "| Click volume | `clicks` (count) | `poisson` | — |\n",
    "| Keyword ranking | any relevance label | `lambdarank` | NDCG@k |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}