{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d22c6ae9",
   "metadata": {},
   "source": [
    "# LightGBM Ads Tutorial\n",
    "\n",
    "End-to-end tutorial using synthetic keyword-ads performance data.\n",
    "\n",
    "**Models covered:**\n",
    "1. CTR prediction (regression)\n",
    "2. Conversion prediction (binary classification)\n",
    "3. Keyword ranking function (score-based)\n",
    "4. Learning-to-Rank with LambdaMART (group-split version)\n",
    "5. Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df58ec9",
   "metadata": {},
   "source": [
    "## 0) Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884d28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27814e01",
   "metadata": {},
   "source": [
    "## 1) Create synthetic ads dataset\n",
    "\n",
    "Each row represents one `(given_word, keyword)` pair with features:\n",
    "- `similarity` – cosine-like similarity between the two words\n",
    "- `competition`, `impressions`, `clicks`, `cpc`, `cost`, `device`, `hour`\n",
    "\n",
    "Targets:\n",
    "- `ctr` – click-through rate (regression)\n",
    "- `has_conversion` – did it convert at least once? (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63d9876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given_words : 50\n",
      "keywords    : 1030\n",
      "\n",
      "Dataset shape: (100000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_word</th>\n",
       "      <th>keyword</th>\n",
       "      <th>similarity</th>\n",
       "      <th>competition</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>cpc</th>\n",
       "      <th>cost</th>\n",
       "      <th>device</th>\n",
       "      <th>hour</th>\n",
       "      <th>ctr</th>\n",
       "      <th>has_conversion</th>\n",
       "      <th>conversions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watch</td>\n",
       "      <td>vacuum for pet hair</td>\n",
       "      <td>0.894986</td>\n",
       "      <td>0.901347</td>\n",
       "      <td>15103</td>\n",
       "      <td>1514</td>\n",
       "      <td>2.182333</td>\n",
       "      <td>3304.051789</td>\n",
       "      <td>desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100245</td>\n",
       "      <td>1</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>supplement</td>\n",
       "      <td>slide guitar</td>\n",
       "      <td>0.902860</td>\n",
       "      <td>0.538472</td>\n",
       "      <td>8103</td>\n",
       "      <td>742</td>\n",
       "      <td>1.105999</td>\n",
       "      <td>820.651490</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7</td>\n",
       "      <td>0.091571</td>\n",
       "      <td>1</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mattress</td>\n",
       "      <td>horseshoe necklace</td>\n",
       "      <td>0.532406</td>\n",
       "      <td>0.753773</td>\n",
       "      <td>18052</td>\n",
       "      <td>1179</td>\n",
       "      <td>1.812916</td>\n",
       "      <td>2137.427676</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4</td>\n",
       "      <td>0.065311</td>\n",
       "      <td>1</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunglasses</td>\n",
       "      <td>monitor arm</td>\n",
       "      <td>0.275778</td>\n",
       "      <td>0.458050</td>\n",
       "      <td>7866</td>\n",
       "      <td>589</td>\n",
       "      <td>1.534560</td>\n",
       "      <td>903.855895</td>\n",
       "      <td>mobile</td>\n",
       "      <td>19</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunglasses</td>\n",
       "      <td>pixel phone</td>\n",
       "      <td>0.715391</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>8275</td>\n",
       "      <td>796</td>\n",
       "      <td>1.624289</td>\n",
       "      <td>1292.933963</td>\n",
       "      <td>desktop</td>\n",
       "      <td>6</td>\n",
       "      <td>0.096193</td>\n",
       "      <td>1</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   given_word              keyword  similarity  competition  impressions  \\\n",
       "0       watch  vacuum for pet hair    0.894986     0.901347        15103   \n",
       "1  supplement         slide guitar    0.902860     0.538472         8103   \n",
       "2    mattress   horseshoe necklace    0.532406     0.753773        18052   \n",
       "3  sunglasses          monitor arm    0.275778     0.458050         7866   \n",
       "4  sunglasses          pixel phone    0.715391     0.758914         8275   \n",
       "\n",
       "   clicks       cpc         cost   device  hour       ctr  has_conversion  \\\n",
       "0    1514  2.182333  3304.051789  desktop     1  0.100245               1   \n",
       "1     742  1.105999   820.651490  desktop     7  0.091571               1   \n",
       "2    1179  1.812916  2137.427676  desktop     4  0.065311               1   \n",
       "3     589  1.534560   903.855895   mobile    19  0.074879               1   \n",
       "4     796  1.624289  1292.933963  desktop     6  0.096193               1   \n",
       "\n",
       "   conversions  \n",
       "0         1035  \n",
       "1          566  \n",
       "2          395  \n",
       "3          115  \n",
       "4          427  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Load word lists from files\n",
    "with open(\"given_words.json\") as f:\n",
    "    given_words = np.array(json.load(f))\n",
    "\n",
    "with open(\"keywords.json\") as f:\n",
    "    keywords = np.array(json.load(f))\n",
    "\n",
    "print(f\"given_words : {len(given_words)}\")\n",
    "print(f\"keywords    : {len(keywords)}\")\n",
    "\n",
    "def make_ads_dataset(n=100_000):\n",
    "    given = rng.choice(given_words, size=n)\n",
    "    kw    = rng.choice(keywords, size=n)\n",
    "\n",
    "    # Similarity: random base (no hardcoded pair boosts with large vocabularies)\n",
    "    similarity = rng.uniform(0.05, 0.95, size=n)\n",
    "\n",
    "    impressions = rng.integers(50, 20000, size=n)\n",
    "    device      = rng.choice([\"mobile\", \"desktop\"], size=n, p=[0.7, 0.3])\n",
    "    hour        = rng.integers(0, 24, size=n)\n",
    "\n",
    "    competition = rng.uniform(0.1, 1.0, size=n)\n",
    "    cpc = np.clip(\n",
    "        0.2 + 2.0 * competition + 0.5 * (1 - similarity) + rng.normal(0, 0.15, size=n),\n",
    "        0.05, None\n",
    "    )\n",
    "\n",
    "    device_boost = np.where(device == \"mobile\", 0.02, 0.0)\n",
    "    hour_boost   = np.where((hour >= 19) & (hour <= 23), 0.01, 0.0)\n",
    "    ctr = np.clip(\n",
    "        0.01 + 0.10 * similarity + device_boost + hour_boost + rng.normal(0, 0.01, size=n),\n",
    "        0.0005, 0.30\n",
    "    )\n",
    "\n",
    "    clicks = rng.binomial(impressions, p=ctr)\n",
    "    cost   = clicks * cpc\n",
    "\n",
    "    conv_p = 1 / (1 + np.exp(-(-2.0 + 4.0 * similarity - 0.4 * cpc)))\n",
    "    conversions    = rng.binomial(np.maximum(clicks, 1), p=np.clip(conv_p, 0.0001, 0.8))\n",
    "    has_conversion = (conversions > 0).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"given_word\":     given,\n",
    "        \"keyword\":        kw,\n",
    "        \"similarity\":     similarity,\n",
    "        \"competition\":    competition,\n",
    "        \"impressions\":    impressions,\n",
    "        \"clicks\":         clicks,\n",
    "        \"cpc\":            cpc,\n",
    "        \"cost\":           cost,\n",
    "        \"device\":         device,\n",
    "        \"hour\":           hour,\n",
    "        \"ctr\":            np.where(impressions > 0, clicks / impressions, 0.0),\n",
    "        \"has_conversion\": has_conversion,\n",
    "        \"conversions\":    conversions,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "df = make_ads_dataset(100_000)\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1988b4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>competition</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>cpc</th>\n",
       "      <th>cost</th>\n",
       "      <th>hour</th>\n",
       "      <th>ctr</th>\n",
       "      <th>has_conversion</th>\n",
       "      <th>conversions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499401</td>\n",
       "      <td>0.548108</td>\n",
       "      <td>10042.043230</td>\n",
       "      <td>763.562430</td>\n",
       "      <td>1.545873</td>\n",
       "      <td>1147.029746</td>\n",
       "      <td>11.501840</td>\n",
       "      <td>0.076045</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>347.762080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.259928</td>\n",
       "      <td>0.259939</td>\n",
       "      <td>5767.395724</td>\n",
       "      <td>556.924017</td>\n",
       "      <td>0.556984</td>\n",
       "      <td>942.280951</td>\n",
       "      <td>6.902771</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.067153</td>\n",
       "      <td>388.698936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.050020</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.273222</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>5028.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>1.094631</td>\n",
       "      <td>421.735371</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.053116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.498087</td>\n",
       "      <td>0.546702</td>\n",
       "      <td>10075.000000</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>1.542200</td>\n",
       "      <td>907.503238</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.075877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.724805</td>\n",
       "      <td>0.773350</td>\n",
       "      <td>15048.000000</td>\n",
       "      <td>1120.000000</td>\n",
       "      <td>1.997313</td>\n",
       "      <td>1636.166584</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.099104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.949998</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>19999.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3.097405</td>\n",
       "      <td>6457.487686</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          similarity    competition    impressions         clicks  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.499401       0.548108   10042.043230     763.562430   \n",
       "std         0.259928       0.259939    5767.395724     556.924017   \n",
       "min         0.050020       0.100002      50.000000       0.000000   \n",
       "25%         0.273222       0.323529    5028.000000     308.000000   \n",
       "50%         0.498087       0.546702   10075.000000     654.000000   \n",
       "75%         0.724805       0.773350   15048.000000    1120.000000   \n",
       "max         0.949998       0.999993   19999.000000    3061.000000   \n",
       "\n",
       "                 cpc           cost           hour            ctr  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        1.545873    1147.029746      11.501840       0.076045   \n",
       "std         0.556984     942.280951       6.902771       0.029938   \n",
       "min         0.060418       0.000000       0.000000       0.000000   \n",
       "25%         1.094631     421.735371       6.000000       0.053116   \n",
       "50%         1.542200     907.503238      12.000000       0.075877   \n",
       "75%         1.997313    1636.166584      17.000000       0.099104   \n",
       "max         3.097405    6457.487686      23.000000       0.272727   \n",
       "\n",
       "       has_conversion    conversions  \n",
       "count   100000.000000  100000.000000  \n",
       "mean         0.995470     347.762080  \n",
       "std          0.067153     388.698936  \n",
       "min          0.000000       0.000000  \n",
       "25%          1.000000      61.000000  \n",
       "50%          1.000000     191.000000  \n",
       "75%          1.000000     510.000000  \n",
       "max          1.000000    2417.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21903c20",
   "metadata": {},
   "source": [
    "## 2) Prepare features\n",
    "\n",
    "LightGBM handles categorical features natively when they are `pandas.Categorical` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16f0637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (80000, 10)  |  Test: (20000, 10)\n",
      "Conversion rate (train): 0.996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"given_word\", \"keyword\", \"similarity\", \"competition\",\n",
    "    \"impressions\", \"clicks\", \"cpc\", \"cost\", \"device\", \"hour\"\n",
    "]\n",
    "CAT_COLS = [\"given_word\", \"keyword\", \"device\"]\n",
    "\n",
    "X = df[FEATURE_COLS].copy()\n",
    "for c in CAT_COLS:\n",
    "    X[c] = X[c].astype(\"category\")\n",
    "\n",
    "y_ctr  = df[\"ctr\"].values\n",
    "y_conv = df[\"has_conversion\"].values\n",
    "\n",
    "X_train, X_test, y_ctr_train, y_ctr_test = train_test_split(\n",
    "    X, y_ctr, test_size=0.2, random_state=42\n",
    ")\n",
    "# reuse the same split indices for the conversion target\n",
    "y_conv_train = y_conv[X_train.index]\n",
    "y_conv_test  = y_conv[X_test.index]\n",
    "\n",
    "print(f\"Train: {X_train.shape}  |  Test: {X_test.shape}\")\n",
    "print(f\"Conversion rate (train): {y_conv_train.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde0599",
   "metadata": {},
   "source": [
    "## 3) Model A — CTR prediction (regression)\n",
    "\n",
    "CTR is continuous and bounded in (0, 1). We weight each sample by `impressions` so high-volume rows have more influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ef3b7",
   "metadata": {},
   "outputs": [],
   "source": "import lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\n\nreg = lgb.LGBMRegressor(\n    n_estimators=2000,\n    learning_rate=0.03,\n    num_leaves=63,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    random_state=42,\n    verbose=-1,\n)\n\nreg.fit(\n    X_train, y_ctr_train,\n    sample_weight=X_train[\"impressions\"],\n    eval_set=[(X_test, y_ctr_test)],\n    eval_sample_weight=[X_test[\"impressions\"]],\n    eval_metric=\"l2\",\n    categorical_feature=CAT_COLS,\n    callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False),\n               lgb.log_evaluation(period=200)],\n)\n\npred_ctr = reg.predict(X_test)\nrmse = mean_squared_error(y_ctr_test, pred_ctr) ** 0.5\nprint(f\"\\nCTR RMSE : {rmse:.6f}\")\nprint(f\"Best iter: {reg.best_iteration_}\")"
  },
  {
   "cell_type": "markdown",
   "id": "344cfe2d",
   "metadata": {},
   "source": [
    "## 4) Model B — Conversion prediction (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe96b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train, y_conv_train,\n",
    "    eval_set=[(X_test, y_conv_test)],\n",
    "    eval_metric=\"auc\",\n",
    "    categorical_feature=CAT_COLS,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "               lgb.log_evaluation(period=200)],\n",
    ")\n",
    "\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "print(f\"\\nAUC   : {roc_auc_score(y_conv_test, proba):.4f}\")\n",
    "print(f\"PR-AUC: {average_precision_score(y_conv_test, proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4502d",
   "metadata": {},
   "source": [
    "## 5) Rank keywords for a given word\n",
    "\n",
    "For a new `given_word`, score a list of candidate keywords using:\n",
    "- `pred_ctr` from the regression model\n",
    "- `pred_conv_prob` from the classifier\n",
    "- `score = pred_ctr × pred_conv_prob` (customize to ROAS, profit, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926eba49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_keywords_for_given(given_word: str, candidates: list[str], base_features: dict) -> pd.DataFrame:\n",
    "    \"\"\"Score and rank candidate keywords for a given word.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    given_word   : The query / seed word.\n",
    "    candidates   : List of keyword strings to evaluate.\n",
    "    base_features: Dict with values for all feature columns except\n",
    "                   given_word and keyword.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame sorted by score descending.\n",
    "    \"\"\"\n",
    "    rows = [\n",
    "        {**base_features, \"given_word\": given_word, \"keyword\": kw}\n",
    "        for kw in candidates\n",
    "    ]\n",
    "    Xcand = pd.DataFrame(rows)[FEATURE_COLS]\n",
    "    for c in CAT_COLS:\n",
    "        Xcand[c] = Xcand[c].astype(\"category\")\n",
    "\n",
    "    ctr_hat  = reg.predict(Xcand)\n",
    "    conv_hat = clf.predict_proba(Xcand)[:, 1]\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"given_word\":     given_word,\n",
    "        \"keyword\":        candidates,\n",
    "        \"pred_ctr\":       ctr_hat,\n",
    "        \"pred_conv_prob\": conv_hat,\n",
    "        \"score\":          ctr_hat * conv_hat,   # ← swap for ROAS/profit\n",
    "    })\n",
    "    return out.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "candidates = [\"refinance\", \"mortgage\", \"card\", \"booking\",\n",
    "              \"ticket\", \"policy\", \"espresso\", \"dslr\"]\n",
    "\n",
    "base = {\n",
    "    \"similarity\":  0.7,\n",
    "    \"competition\": 0.6,\n",
    "    \"impressions\": 5000,\n",
    "    \"clicks\":      0,     # planning mode — no historic clicks yet\n",
    "    \"cpc\":         2.0,\n",
    "    \"cost\":        0.0,\n",
    "    \"device\":      \"mobile\",\n",
    "    \"hour\":        21,\n",
    "}\n",
    "\n",
    "ranked = rank_keywords_for_given(\"loan\", candidates, base)\n",
    "ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e32e47d",
   "metadata": {},
   "source": [
    "## 6) Learning-to-Rank with LambdaMART\n",
    "\n",
    "A proper LambdaMART setup requires:\n",
    "1. **Group-based train/test split** — keep all rows for a `given_word` in the same split.\n",
    "2. **Group sizes array** — number of candidate keywords per query, in order.\n",
    "3. **Relevance labels** — here we use `ctr`; in production use ROAS or conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df8cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRanker\n",
    "\n",
    "# ── 6a) Group-based train/test split ──────────────────────────────────────────\n",
    "unique_given = df[\"given_word\"].unique()\n",
    "rng_split    = np.random.default_rng(0)\n",
    "rng_split.shuffle(unique_given)\n",
    "\n",
    "split_idx    = int(len(unique_given) * 0.8)\n",
    "train_words  = set(unique_given[:split_idx])\n",
    "test_words   = set(unique_given[split_idx:])\n",
    "\n",
    "df_rank = df.sort_values(\"given_word\").copy()\n",
    "\n",
    "mask_train = df_rank[\"given_word\"].isin(train_words)\n",
    "df_r_train = df_rank[mask_train].copy()\n",
    "df_r_test  = df_rank[~mask_train].copy()\n",
    "\n",
    "print(f\"Ranker train rows: {len(df_r_train)}  |  test rows: {len(df_r_test)}\")\n",
    "print(f\"Train given_words: {sorted(train_words)}\")\n",
    "print(f\"Test  given_words: {sorted(test_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766f3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 6b) Build feature matrices and group size arrays ──────────────────────────\n",
    "def build_rank_arrays(subset: pd.DataFrame):\n",
    "    Xr = subset[FEATURE_COLS].copy()\n",
    "    for c in CAT_COLS:\n",
    "        Xr[c] = Xr[c].astype(\"category\")\n",
    "    y  = subset[\"ctr\"].values\n",
    "    groups = subset.groupby(\"given_word\", sort=True).size().tolist()\n",
    "    return Xr, y, groups\n",
    "\n",
    "Xr_train, yr_train, groups_train = build_rank_arrays(df_r_train)\n",
    "Xr_test,  yr_test,  groups_test  = build_rank_arrays(df_r_test)\n",
    "\n",
    "print(f\"Group sizes (train): {groups_train}\")\n",
    "print(f\"Group sizes (test) : {groups_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf5cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 6c) Train LambdaMART ranker ───────────────────────────────────────────────\n",
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[3, 5, 10],\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "ranker.fit(\n",
    "    Xr_train, yr_train,\n",
    "    group=groups_train,\n",
    "    eval_set=[(Xr_test, yr_test)],\n",
    "    eval_group=[groups_test],\n",
    "    categorical_feature=CAT_COLS,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False),\n",
    "               lgb.log_evaluation(period=200)],\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration: {ranker.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf40b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 6d) Inspect ranker scores for one test given_word ─────────────────────────\n",
    "sample_word = list(test_words)[0]\n",
    "df_sample   = df_r_test[df_r_test[\"given_word\"] == sample_word].copy()\n",
    "\n",
    "Xs = df_sample[FEATURE_COLS].copy()\n",
    "for c in CAT_COLS:\n",
    "    Xs[c] = Xs[c].astype(\"category\")\n",
    "\n",
    "df_sample[\"ranker_score\"] = ranker.predict(Xs)\n",
    "df_sample[[\"given_word\", \"keyword\", \"ctr\", \"ranker_score\"]] \\\n",
    "    .sort_values(\"ranker_score\", ascending=False) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7c66d",
   "metadata": {},
   "source": [
    "## 7) Feature importance\n",
    "\n",
    "Using **gain** (total reduction in loss attributed to each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025469cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_importance(model, title: str):\n",
    "    fi = pd.DataFrame({\n",
    "        \"feature\":    model.feature_name_,\n",
    "        \"importance\": model.booster_.feature_importance(importance_type=\"gain\"),\n",
    "    }).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(fi.to_string(index=False))\n",
    "    return fi\n",
    "\n",
    "fi_reg    = show_importance(reg,    \"CTR Regression\")\n",
    "fi_clf    = show_importance(clf,    \"Conversion Classifier\")\n",
    "fi_ranker = show_importance(ranker, \"LambdaMART Ranker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270d690",
   "metadata": {},
   "source": [
    "## Quick-reference: choosing the right setup\n",
    "\n",
    "| Success metric | Target variable | LightGBM objective | Eval metric |\n",
    "|---|---|---|---|\n",
    "| CTR | `ctr` (float) | `regression` | RMSE / MAE |\n",
    "| Conversion | `has_conversion` (0/1) | `binary` | AUC / PR-AUC |\n",
    "| ROAS / Profit | continuous value | `regression` or `tweedie` | RMSE |\n",
    "| Click volume | `clicks` (count) | `poisson` | — |\n",
    "| Keyword ranking | any relevance label | `lambdarank` | NDCG@k |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}