{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d22c6ae9",
   "metadata": {},
   "source": [
    "# LightGBM Ads Tutorial\n",
    "\n",
    "End-to-end tutorial using synthetic keyword-ads performance data.\n",
    "\n",
    "**Models covered:**\n",
    "1. CTR prediction (regression)\n",
    "2. Conversion prediction (binary classification)\n",
    "3. Keyword ranking function (score-based)\n",
    "4. Learning-to-Rank with LambdaMART (group-split version)\n",
    "5. Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df58ec9",
   "metadata": {},
   "source": [
    "## 0) Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "884d28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27814e01",
   "metadata": {},
   "source": [
    "## 1) Create synthetic ads dataset\n",
    "\n",
    "Each row represents one `(given_word, keyword)` pair with features:\n",
    "- `similarity` – cosine-like similarity between the two words\n",
    "- `competition`, `impressions`, `clicks`, `cpc`, `cost`, `device`, `hour`\n",
    "\n",
    "Targets:\n",
    "- `ctr` – click-through rate (regression)\n",
    "- `has_conversion` – did it convert at least once? (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63d9876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given_words : 50\n",
      "keywords    : 1030\n",
      "\n",
      "Dataset shape: (100000, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_word</th>\n",
       "      <th>keyword</th>\n",
       "      <th>similarity</th>\n",
       "      <th>competition</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>cpc</th>\n",
       "      <th>cost</th>\n",
       "      <th>device</th>\n",
       "      <th>hour</th>\n",
       "      <th>ctr</th>\n",
       "      <th>has_conversion</th>\n",
       "      <th>conversions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watch</td>\n",
       "      <td>vacuum for pet hair</td>\n",
       "      <td>0.894986</td>\n",
       "      <td>0.901347</td>\n",
       "      <td>15103</td>\n",
       "      <td>1514</td>\n",
       "      <td>2.182333</td>\n",
       "      <td>3304.051789</td>\n",
       "      <td>desktop</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100245</td>\n",
       "      <td>1</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>supplement</td>\n",
       "      <td>slide guitar</td>\n",
       "      <td>0.902860</td>\n",
       "      <td>0.538472</td>\n",
       "      <td>8103</td>\n",
       "      <td>742</td>\n",
       "      <td>1.105999</td>\n",
       "      <td>820.651490</td>\n",
       "      <td>desktop</td>\n",
       "      <td>7</td>\n",
       "      <td>0.091571</td>\n",
       "      <td>1</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mattress</td>\n",
       "      <td>horseshoe necklace</td>\n",
       "      <td>0.532406</td>\n",
       "      <td>0.753773</td>\n",
       "      <td>18052</td>\n",
       "      <td>1179</td>\n",
       "      <td>1.812916</td>\n",
       "      <td>2137.427676</td>\n",
       "      <td>desktop</td>\n",
       "      <td>4</td>\n",
       "      <td>0.065311</td>\n",
       "      <td>1</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sunglasses</td>\n",
       "      <td>monitor arm</td>\n",
       "      <td>0.275778</td>\n",
       "      <td>0.458050</td>\n",
       "      <td>7866</td>\n",
       "      <td>589</td>\n",
       "      <td>1.534560</td>\n",
       "      <td>903.855895</td>\n",
       "      <td>mobile</td>\n",
       "      <td>19</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sunglasses</td>\n",
       "      <td>pixel phone</td>\n",
       "      <td>0.715391</td>\n",
       "      <td>0.758914</td>\n",
       "      <td>8275</td>\n",
       "      <td>796</td>\n",
       "      <td>1.624289</td>\n",
       "      <td>1292.933963</td>\n",
       "      <td>desktop</td>\n",
       "      <td>6</td>\n",
       "      <td>0.096193</td>\n",
       "      <td>1</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   given_word              keyword  similarity  competition  impressions  \\\n",
       "0       watch  vacuum for pet hair    0.894986     0.901347        15103   \n",
       "1  supplement         slide guitar    0.902860     0.538472         8103   \n",
       "2    mattress   horseshoe necklace    0.532406     0.753773        18052   \n",
       "3  sunglasses          monitor arm    0.275778     0.458050         7866   \n",
       "4  sunglasses          pixel phone    0.715391     0.758914         8275   \n",
       "\n",
       "   clicks       cpc         cost   device  hour       ctr  has_conversion  \\\n",
       "0    1514  2.182333  3304.051789  desktop     1  0.100245               1   \n",
       "1     742  1.105999   820.651490  desktop     7  0.091571               1   \n",
       "2    1179  1.812916  2137.427676  desktop     4  0.065311               1   \n",
       "3     589  1.534560   903.855895   mobile    19  0.074879               1   \n",
       "4     796  1.624289  1292.933963  desktop     6  0.096193               1   \n",
       "\n",
       "   conversions  \n",
       "0         1035  \n",
       "1          566  \n",
       "2          395  \n",
       "3          115  \n",
       "4          427  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Load word lists from files\n",
    "with open(\"given_words.json\") as f:\n",
    "    given_words = np.array(json.load(f))\n",
    "\n",
    "with open(\"keywords.json\") as f:\n",
    "    keywords = np.array(json.load(f))\n",
    "\n",
    "print(f\"given_words : {len(given_words)}\")\n",
    "print(f\"keywords    : {len(keywords)}\")\n",
    "\n",
    "def make_ads_dataset(n=100_000):\n",
    "    given = rng.choice(given_words, size=n)\n",
    "    kw    = rng.choice(keywords, size=n)\n",
    "\n",
    "    # Similarity: random base (no hardcoded pair boosts with large vocabularies)\n",
    "    similarity = rng.uniform(0.05, 0.95, size=n)\n",
    "\n",
    "    impressions = rng.integers(50, 20000, size=n)\n",
    "    device      = rng.choice([\"mobile\", \"desktop\"], size=n, p=[0.7, 0.3])\n",
    "    hour        = rng.integers(0, 24, size=n)\n",
    "\n",
    "    competition = rng.uniform(0.1, 1.0, size=n)\n",
    "    cpc = np.clip(\n",
    "        0.2 + 2.0 * competition + 0.5 * (1 - similarity) + rng.normal(0, 0.15, size=n),\n",
    "        0.05, None\n",
    "    )\n",
    "\n",
    "    device_boost = np.where(device == \"mobile\", 0.02, 0.0)\n",
    "    hour_boost   = np.where((hour >= 19) & (hour <= 23), 0.01, 0.0)\n",
    "    ctr = np.clip(\n",
    "        0.01 + 0.10 * similarity + device_boost + hour_boost + rng.normal(0, 0.01, size=n),\n",
    "        0.0005, 0.30\n",
    "    )\n",
    "\n",
    "    clicks = rng.binomial(impressions, p=ctr)\n",
    "    cost   = clicks * cpc\n",
    "\n",
    "    conv_p = 1 / (1 + np.exp(-(-2.0 + 4.0 * similarity - 0.4 * cpc)))\n",
    "    conversions    = rng.binomial(np.maximum(clicks, 1), p=np.clip(conv_p, 0.0001, 0.8))\n",
    "    has_conversion = (conversions > 0).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"given_word\":     given,\n",
    "        \"keyword\":        kw,\n",
    "        \"similarity\":     similarity,\n",
    "        \"competition\":    competition,\n",
    "        \"impressions\":    impressions,\n",
    "        \"clicks\":         clicks,\n",
    "        \"cpc\":            cpc,\n",
    "        \"cost\":           cost,\n",
    "        \"device\":         device,\n",
    "        \"hour\":           hour,\n",
    "        \"ctr\":            np.where(impressions > 0, clicks / impressions, 0.0),\n",
    "        \"has_conversion\": has_conversion,\n",
    "        \"conversions\":    conversions,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "df = make_ads_dataset(100_000)\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1988b4c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>competition</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "      <th>cpc</th>\n",
       "      <th>cost</th>\n",
       "      <th>hour</th>\n",
       "      <th>ctr</th>\n",
       "      <th>has_conversion</th>\n",
       "      <th>conversions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499401</td>\n",
       "      <td>0.548108</td>\n",
       "      <td>10042.043230</td>\n",
       "      <td>763.562430</td>\n",
       "      <td>1.545873</td>\n",
       "      <td>1147.029746</td>\n",
       "      <td>11.501840</td>\n",
       "      <td>0.076045</td>\n",
       "      <td>0.995470</td>\n",
       "      <td>347.762080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.259928</td>\n",
       "      <td>0.259939</td>\n",
       "      <td>5767.395724</td>\n",
       "      <td>556.924017</td>\n",
       "      <td>0.556984</td>\n",
       "      <td>942.280951</td>\n",
       "      <td>6.902771</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.067153</td>\n",
       "      <td>388.698936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.050020</td>\n",
       "      <td>0.100002</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.273222</td>\n",
       "      <td>0.323529</td>\n",
       "      <td>5028.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>1.094631</td>\n",
       "      <td>421.735371</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.053116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.498087</td>\n",
       "      <td>0.546702</td>\n",
       "      <td>10075.000000</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>1.542200</td>\n",
       "      <td>907.503238</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.075877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.724805</td>\n",
       "      <td>0.773350</td>\n",
       "      <td>15048.000000</td>\n",
       "      <td>1120.000000</td>\n",
       "      <td>1.997313</td>\n",
       "      <td>1636.166584</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.099104</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>510.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.949998</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>19999.000000</td>\n",
       "      <td>3061.000000</td>\n",
       "      <td>3.097405</td>\n",
       "      <td>6457.487686</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          similarity    competition    impressions         clicks  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.499401       0.548108   10042.043230     763.562430   \n",
       "std         0.259928       0.259939    5767.395724     556.924017   \n",
       "min         0.050020       0.100002      50.000000       0.000000   \n",
       "25%         0.273222       0.323529    5028.000000     308.000000   \n",
       "50%         0.498087       0.546702   10075.000000     654.000000   \n",
       "75%         0.724805       0.773350   15048.000000    1120.000000   \n",
       "max         0.949998       0.999993   19999.000000    3061.000000   \n",
       "\n",
       "                 cpc           cost           hour            ctr  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        1.545873    1147.029746      11.501840       0.076045   \n",
       "std         0.556984     942.280951       6.902771       0.029938   \n",
       "min         0.060418       0.000000       0.000000       0.000000   \n",
       "25%         1.094631     421.735371       6.000000       0.053116   \n",
       "50%         1.542200     907.503238      12.000000       0.075877   \n",
       "75%         1.997313    1636.166584      17.000000       0.099104   \n",
       "max         3.097405    6457.487686      23.000000       0.272727   \n",
       "\n",
       "       has_conversion    conversions  \n",
       "count   100000.000000  100000.000000  \n",
       "mean         0.995470     347.762080  \n",
       "std          0.067153     388.698936  \n",
       "min          0.000000       0.000000  \n",
       "25%          1.000000      61.000000  \n",
       "50%          1.000000     191.000000  \n",
       "75%          1.000000     510.000000  \n",
       "max          1.000000    2417.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21903c20",
   "metadata": {},
   "source": [
    "## 2) Prepare features\n",
    "\n",
    "LightGBM handles categorical features natively when they are `pandas.Categorical` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16f0637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (80000, 10)  |  Test: (20000, 10)\n",
      "Conversion rate (train): 0.996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"given_word\", \"keyword\", \"similarity\", \"competition\",\n",
    "    \"impressions\", \"clicks\", \"cpc\", \"cost\", \"device\", \"hour\"\n",
    "]\n",
    "CAT_COLS = [\"given_word\", \"keyword\", \"device\"]\n",
    "\n",
    "X = df[FEATURE_COLS].copy()\n",
    "for c in CAT_COLS:\n",
    "    X[c] = X[c].astype(\"category\")\n",
    "\n",
    "y_ctr  = df[\"ctr\"].values\n",
    "y_conv = df[\"has_conversion\"].values\n",
    "\n",
    "X_train, X_test, y_ctr_train, y_ctr_test = train_test_split(\n",
    "    X, y_ctr, test_size=0.2, random_state=42\n",
    ")\n",
    "# reuse the same split indices for the conversion target\n",
    "y_conv_train = y_conv[X_train.index]\n",
    "y_conv_test  = y_conv[X_test.index]\n",
    "\n",
    "print(f\"Train: {X_train.shape}  |  Test: {X_test.shape}\")\n",
    "print(f\"Conversion rate (train): {y_conv_train.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde0599",
   "metadata": {},
   "source": [
    "## 3) Model A — CTR prediction (regression)\n",
    "\n",
    "CTR is continuous and bounded in (0, 1). We weight each sample by `impressions` so high-volume rows have more influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac2ef3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's l2: 1.00769e-05\n",
      "[400]\tvalid_0's l2: 4.18689e-06\n",
      "[600]\tvalid_0's l2: 2.45286e-06\n",
      "[800]\tvalid_0's l2: 1.8003e-06\n",
      "[1000]\tvalid_0's l2: 1.52953e-06\n",
      "[1200]\tvalid_0's l2: 1.39242e-06\n",
      "[1400]\tvalid_0's l2: 1.32024e-06\n",
      "[1600]\tvalid_0's l2: 1.27857e-06\n",
      "[1800]\tvalid_0's l2: 1.25081e-06\n",
      "[2000]\tvalid_0's l2: 1.23382e-06\n",
      "\n",
      "CTR RMSE : 0.002305\n",
      "Best iter: 1999\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = lgb.LGBMRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "reg.fit(\n",
    "    X_train, y_ctr_train,\n",
    "    sample_weight=X_train[\"impressions\"],\n",
    "    eval_set=[(X_test, y_ctr_test)],\n",
    "    eval_sample_weight=[X_test[\"impressions\"]],\n",
    "    eval_metric=\"l2\",\n",
    "    categorical_feature=CAT_COLS,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False),\n",
    "               lgb.log_evaluation(period=200)],\n",
    ")\n",
    "\n",
    "pred_ctr = reg.predict(X_test)\n",
    "rmse = mean_squared_error(y_ctr_test, pred_ctr) ** 0.5\n",
    "print(f\"\\nCTR RMSE : {rmse:.6f}\")\n",
    "print(f\"Best iter: {reg.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cfe2d",
   "metadata": {},
   "source": [
    "## 4) Model B — Conversion prediction (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe96b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC   : 0.9969\n",
      "PR-AUC: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train, y_conv_train,\n",
    "    eval_set=[(X_test, y_conv_test)],\n",
    "    eval_metric=\"auc\",\n",
    "    categorical_feature=CAT_COLS,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "               lgb.log_evaluation(period=200)],\n",
    ")\n",
    "\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "print(f\"\\nAUC   : {roc_auc_score(y_conv_test, proba):.4f}\")\n",
    "print(f\"PR-AUC: {average_precision_score(y_conv_test, proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4502d",
   "metadata": {},
   "source": [
    "## 5) Rank keywords for a given word\n",
    "\n",
    "For a new `given_word`, score a list of candidate keywords using:\n",
    "- `pred_ctr` from the regression model\n",
    "- `pred_conv_prob` from the classifier\n",
    "- `score = pred_ctr × pred_conv_prob` (customize to ROAS, profit, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926eba49",
   "metadata": {},
   "outputs": [],
   "source": "def rank_keywords_for_given(given_word: str, candidates: dict, base_features: dict) -> pd.DataFrame:\n    \"\"\"Score and rank candidate keywords for a given word.\n\n    Parameters\n    ----------\n    given_word    : The query / seed word.\n    candidates    : Dict of {keyword: similarity_score} pairs.\n    base_features : Dict of feature values shared across all candidates\n                    (all cols except given_word, keyword, similarity).\n\n    Returns\n    -------\n    DataFrame sorted by score descending.\n    \"\"\"\n    rows = [\n        {**base_features, \"given_word\": given_word, \"keyword\": kw, \"similarity\": sim}\n        for kw, sim in candidates.items()\n    ]\n    Xcand = pd.DataFrame(rows)[FEATURE_COLS]\n    for c in CAT_COLS:\n        Xcand[c] = Xcand[c].astype(\"category\")\n\n    ctr_hat  = reg.predict(Xcand)\n    conv_hat = clf.predict_proba(Xcand)[:, 1]\n\n    return pd.DataFrame({\n        \"given_word\":     given_word,\n        \"keyword\":        list(candidates.keys()),\n        \"similarity\":     list(candidates.values()),\n        \"pred_ctr\":       ctr_hat,\n        \"pred_conv_prob\": conv_hat,\n        \"score\":          ctr_hat * conv_hat,\n    }).sort_values(\"score\", ascending=False).reset_index(drop=True)\n\n\n# Per-keyword similarity scores (in practice, compute these from word embeddings)\ncandidates = {\n    \"white sneakers\":    0.95,\n    \"running shoes\":     0.82,\n    \"canvas shoes\":      0.74,\n    \"hiking boots\":      0.55,\n    \"yoga mat\":          0.20,\n    \"leather wallet\":    0.10,\n    \"wireless earbuds\":  0.08,\n    \"gaming mouse\":      0.05,\n}\n\nbase = {\n    \"competition\": 0.6,\n    \"impressions\": 5000,\n    \"clicks\":      0,\n    \"cpc\":         2.0,\n    \"cost\":        0.0,\n    \"device\":      \"mobile\",\n    \"hour\":        21,\n}\n\nranked = rank_keywords_for_given(\"sneakers\", candidates, base)\nranked"
  },
  {
   "cell_type": "markdown",
   "id": "3e32e47d",
   "metadata": {},
   "source": [
    "## 6) Learning-to-Rank with LambdaMART\n",
    "\n",
    "A proper LambdaMART setup requires:\n",
    "1. **Group-based train/test split** — keep all rows for a `given_word` in the same split.\n",
    "2. **Group sizes array** — number of candidate keywords per query, in order.\n",
    "3. **Relevance labels** — here we use `ctr`; in production use ROAS or conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7df8cb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranker train rows: 80092  |  test rows: 19908\n",
      "Train given_words: ['boots', 'camera', 'camping', 'candle', 'coffee', 'desk', 'dress', 'fishing', 'gaming', 'gift', 'guitar', 'handbag', 'headphones', 'jacket', 'jewelry', 'keyboard', 'laptop', 'luggage', 'makeup', 'mattress', 'monitor', 'necklace', 'pants', 'perfume', 'pet', 'phone', 'plant', 'printer', 'protein', 'running', 'shoes', 'skincare', 'sneakers', 'sunglasses', 'supplement', 'toy', 'vitamin', 'wallet', 'watch', 'yoga']\n",
      "Test  given_words: ['baby', 'backpack', 'bicycle', 'blender', 'book', 'ring', 'shirt', 'sofa', 'tent', 'vacuum']\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRanker\n",
    "\n",
    "# ── 6a) Group-based train/test split ──────────────────────────────────────────\n",
    "unique_given = df[\"given_word\"].unique()\n",
    "rng_split    = np.random.default_rng(0)\n",
    "rng_split.shuffle(unique_given)\n",
    "\n",
    "split_idx    = int(len(unique_given) * 0.8)\n",
    "train_words  = set(unique_given[:split_idx])\n",
    "test_words   = set(unique_given[split_idx:])\n",
    "\n",
    "df_rank = df.sort_values(\"given_word\").copy()\n",
    "\n",
    "mask_train = df_rank[\"given_word\"].isin(train_words)\n",
    "df_r_train = df_rank[mask_train].copy()\n",
    "df_r_test  = df_rank[~mask_train].copy()\n",
    "\n",
    "print(f\"Ranker train rows: {len(df_r_train)}  |  test rows: {len(df_r_test)}\")\n",
    "print(f\"Train given_words: {sorted(train_words)}\")\n",
    "print(f\"Test  given_words: {sorted(test_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "766f3211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label range: 0 – 4  (grades 0–4)\n",
      "Group sizes (train): [2077, 1977, 2026, 1925, 2017, 1916, 1993, 2019, 2022, 1946, 1978, 1976, 2089, 1906, 2006, 1985, 2069, 2056, 1932, 2027, 2093, 2046, 1986, 2097, 2021, 1973, 2031, 2016, 2092, 1976, 1963, 2021, 1938, 1998, 1975, 1984, 1962, 1979, 1967, 2032]\n",
      "Group sizes (test) : [2002, 1956, 2011, 2028, 1987, 1920, 2081, 1967, 1957, 1999]\n"
     ]
    }
   ],
   "source": [
    "# ── 6b) Build feature matrices and group size arrays ──────────────────────────\n",
    "def bin_ctr(ctr_values: np.ndarray, n_bins: int = 5) -> np.ndarray:\n",
    "    \"\"\"Convert continuous CTR into integer relevance grades (0 to n_bins-1).\"\"\"\n",
    "    bins = np.quantile(ctr_values, np.linspace(0, 1, n_bins + 1))\n",
    "    bins = np.unique(bins)  # remove duplicates if any\n",
    "    return np.digitize(ctr_values, bins[1:-1]).astype(int)\n",
    "\n",
    "def build_rank_arrays(subset: pd.DataFrame):\n",
    "    Xr = subset[FEATURE_COLS].copy()\n",
    "    for c in CAT_COLS:\n",
    "        Xr[c] = Xr[c].astype(\"category\")\n",
    "    y      = bin_ctr(subset[\"ctr\"].values)   # integer grades required by LambdaMART\n",
    "    groups = subset.groupby(\"given_word\", sort=True).size().tolist()\n",
    "    return Xr, y, groups\n",
    "\n",
    "Xr_train, yr_train, groups_train = build_rank_arrays(df_r_train)\n",
    "Xr_test,  yr_test,  groups_test  = build_rank_arrays(df_r_test)\n",
    "\n",
    "print(f\"Label range: {yr_train.min()} – {yr_train.max()}  (grades 0–4)\")\n",
    "print(f\"Group sizes (train): {groups_train}\")\n",
    "print(f\"Group sizes (test) : {groups_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccaf5cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best iteration: 2\n"
     ]
    }
   ],
   "source": [
    "# ── 6c) Train LambdaMART ranker ───────────────────────────────────────────────\n",
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "ranker.fit(\n",
    "    Xr_train, yr_train,\n",
    "    group=groups_train,\n",
    "    eval_set=[(Xr_test, yr_test)],\n",
    "    eval_group=[groups_test],\n",
    "    eval_at=[3, 5, 10],\n",
    "    categorical_feature=CAT_COLS,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False),\n",
    "               lgb.log_evaluation(period=200)],\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration: {ranker.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acf40b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_word</th>\n",
       "      <th>keyword</th>\n",
       "      <th>ctr</th>\n",
       "      <th>ranker_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ring</td>\n",
       "      <td>backpack patch</td>\n",
       "      <td>0.114436</td>\n",
       "      <td>0.117172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ring</td>\n",
       "      <td>yoga mat</td>\n",
       "      <td>0.127631</td>\n",
       "      <td>0.117172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ring</td>\n",
       "      <td>bluetooth keyboard</td>\n",
       "      <td>0.115581</td>\n",
       "      <td>0.117172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ring</td>\n",
       "      <td>nursing pillow</td>\n",
       "      <td>0.110617</td>\n",
       "      <td>0.117172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ring</td>\n",
       "      <td>yoga towel</td>\n",
       "      <td>0.126879</td>\n",
       "      <td>0.117172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>ring</td>\n",
       "      <td>birthstone ring</td>\n",
       "      <td>0.073955</td>\n",
       "      <td>-0.113983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>ring</td>\n",
       "      <td>king mattress</td>\n",
       "      <td>0.039341</td>\n",
       "      <td>-0.113983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>ring</td>\n",
       "      <td>espadrilles</td>\n",
       "      <td>0.023457</td>\n",
       "      <td>-0.113983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>ring</td>\n",
       "      <td>yoga pants</td>\n",
       "      <td>0.056410</td>\n",
       "      <td>-0.113983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>ring</td>\n",
       "      <td>travel blanket</td>\n",
       "      <td>0.058575</td>\n",
       "      <td>-0.113983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     given_word             keyword       ctr  ranker_score\n",
       "0          ring      backpack patch  0.114436      0.117172\n",
       "1          ring            yoga mat  0.127631      0.117172\n",
       "2          ring  bluetooth keyboard  0.115581      0.117172\n",
       "3          ring      nursing pillow  0.110617      0.117172\n",
       "4          ring          yoga towel  0.126879      0.117172\n",
       "...         ...                 ...       ...           ...\n",
       "1915       ring     birthstone ring  0.073955     -0.113983\n",
       "1916       ring       king mattress  0.039341     -0.113983\n",
       "1917       ring         espadrilles  0.023457     -0.113983\n",
       "1918       ring          yoga pants  0.056410     -0.113983\n",
       "1919       ring      travel blanket  0.058575     -0.113983\n",
       "\n",
       "[1920 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ── 6d) Inspect ranker scores for one test given_word ─────────────────────────\n",
    "sample_word = list(test_words)[0]\n",
    "df_sample   = df_r_test[df_r_test[\"given_word\"] == sample_word].copy()\n",
    "\n",
    "Xs = df_sample[FEATURE_COLS].copy()\n",
    "for c in CAT_COLS:\n",
    "    Xs[c] = Xs[c].astype(\"category\")\n",
    "\n",
    "df_sample[\"ranker_score\"] = ranker.predict(Xs)\n",
    "df_sample[[\"given_word\", \"keyword\", \"ctr\", \"ranker_score\"]] \\\n",
    "    .sort_values(\"ranker_score\", ascending=False) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7c66d",
   "metadata": {},
   "source": [
    "## 7) Feature importance\n",
    "\n",
    "Using **gain** (total reduction in loss attributed to each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "025469cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CTR Regression ===\n",
      "    feature   importance\n",
      " similarity 6.901257e+06\n",
      "     clicks 2.753261e+06\n",
      "impressions 1.182219e+06\n",
      "     device 7.017221e+05\n",
      "       cost 1.426487e+05\n",
      "        cpc 1.163797e+05\n",
      "       hour 9.276968e+04\n",
      "competition 3.552020e+04\n",
      "    keyword 1.582057e+04\n",
      " given_word 4.588684e+03\n",
      "\n",
      "=== Conversion Classifier ===\n",
      "    feature   importance\n",
      "     clicks 42370.335656\n",
      " similarity 13723.701457\n",
      "        cpc  5637.854656\n",
      "       cost  4073.249611\n",
      "competition  2308.126128\n",
      "impressions  1812.622571\n",
      "       hour  1767.731493\n",
      "    keyword   964.981350\n",
      " given_word   267.031436\n",
      "     device   229.277286\n",
      "\n",
      "=== LambdaMART Ranker ===\n",
      "    feature  importance\n",
      "     clicks  607.021876\n",
      " similarity  401.939956\n",
      "     device   60.238510\n",
      "        cpc   33.235327\n",
      "competition   28.903426\n",
      "       hour   12.042174\n",
      "    keyword    8.719098\n",
      "impressions    8.193921\n",
      "       cost    5.897397\n",
      " given_word    0.000000\n"
     ]
    }
   ],
   "source": [
    "def show_importance(model, title: str):\n",
    "    fi = pd.DataFrame({\n",
    "        \"feature\":    model.feature_name_,\n",
    "        \"importance\": model.booster_.feature_importance(importance_type=\"gain\"),\n",
    "    }).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(fi.to_string(index=False))\n",
    "    return fi\n",
    "\n",
    "fi_reg    = show_importance(reg,    \"CTR Regression\")\n",
    "fi_clf    = show_importance(clf,    \"Conversion Classifier\")\n",
    "fi_ranker = show_importance(ranker, \"LambdaMART Ranker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270d690",
   "metadata": {},
   "source": [
    "## Quick-reference: choosing the right setup\n",
    "\n",
    "| Success metric | Target variable | LightGBM objective | Eval metric |\n",
    "|---|---|---|---|\n",
    "| CTR | `ctr` (float) | `regression` | RMSE / MAE |\n",
    "| Conversion | `has_conversion` (0/1) | `binary` | AUC / PR-AUC |\n",
    "| ROAS / Profit | continuous value | `regression` or `tweedie` | RMSE |\n",
    "| Click volume | `clicks` (count) | `poisson` | — |\n",
    "| Keyword ranking | any relevance label | `lambdarank` | NDCG@k |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z5bym147r7",
   "source": "## 8) Real similarity with sentence embeddings\n\nInstead of hardcoding similarity values, compute them from a pretrained embedding model.\n`all-MiniLM-L6-v2` runs locally, is fast, and understands semantic meaning.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "fm7us2hhkrd",
   "source": "# !pip install sentence-transformers",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "iefncur4vg",
   "source": "from sentence_transformers import SentenceTransformer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Load model once — downloads ~80MB on first run\nembed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n\ndef compute_similarities(given_word: str, keywords: list) -> dict:\n    \"\"\"Compute cosine similarity between given_word and each keyword.\"\"\"\n    texts     = [given_word] + keywords\n    vecs      = embed_model.encode(texts, normalize_embeddings=True)\n    given_vec = vecs[0:1]\n    kw_vecs   = vecs[1:]\n    scores    = cosine_similarity(given_vec, kw_vecs)[0]\n    return dict(zip(keywords, scores.tolist()))\n\n\ngiven_word = \"sneakers\"\nkeywords   = [\n    \"white sneakers\", \"running shoes\", \"canvas shoes\",\n    \"hiking boots\", \"yoga mat\", \"leather wallet\",\n    \"wireless earbuds\", \"gaming mouse\",\n]\n\ncandidates = compute_similarities(given_word, keywords)\n\nfor kw, sim in sorted(candidates.items(), key=lambda x: -x[1]):\n    print(f\"{sim:.3f}  {kw}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "o7ccj6a7ns",
   "source": "# Plug real similarities into the ranker\nbase = {\n    \"competition\": 0.6,\n    \"impressions\": 5000,\n    \"clicks\":      0,\n    \"cpc\":         2.0,\n    \"cost\":        0.0,\n    \"device\":      \"mobile\",\n    \"hour\":        21,\n}\n\nranked = rank_keywords_for_given(given_word, candidates, base)\nranked",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}