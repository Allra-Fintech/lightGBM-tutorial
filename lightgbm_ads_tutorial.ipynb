{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM Ads Tutorial\n",
    "\n",
    "End-to-end tutorial using synthetic keyword-ads performance data.\n",
    "\n",
    "**Models covered:**\n",
    "1. CTR prediction (regression)\n",
    "2. Conversion prediction (binary classification)\n",
    "3. Keyword ranking function (score-based)\n",
    "4. Learning-to-Rank with LambdaMART (group-split version)\n",
    "5. Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lightgbm scikit-learn pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Create synthetic ads dataset\n",
    "\n",
    "Each row represents one `(given_word, keyword)` pair with features:\n",
    "- `similarity` – cosine-like similarity between the two words\n",
    "- `competition`, `impressions`, `clicks`, `cpc`, `cost`, `device`, `hour`\n",
    "\n",
    "Targets:\n",
    "- `ctr` – click-through rate (regression)\n",
    "- `has_conversion` – did it convert at least once? (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def make_ads_dataset(n=8000):\n",
    "    given_words = np.array([\"loan\", \"credit\", \"hotel\", \"flight\", \"shoes\",\n",
    "                             \"insurance\", \"camera\", \"laptop\", \"vitamin\", \"coffee\"])\n",
    "    keywords = np.array([\"refinance\", \"mortgage\", \"card\", \"booking\", \"ticket\",\n",
    "                          \"sneakers\", \"policy\", \"dslr\", \"ultrabook\", \"supplement\", \"espresso\"])\n",
    "\n",
    "    given = rng.choice(given_words, size=n)\n",
    "    kw    = rng.choice(keywords, size=n)\n",
    "\n",
    "    # Similarity: random base + boost for intuitive pairs\n",
    "    base_sim = rng.uniform(0.05, 0.95, size=n)\n",
    "    pair_boost = (\n",
    "        ((given == \"loan\")   & (kw == \"refinance\")) |\n",
    "        ((given == \"hotel\")  & (kw == \"booking\"))   |\n",
    "        ((given == \"flight\") & (kw == \"ticket\"))\n",
    "    )\n",
    "    similarity = np.clip(base_sim + pair_boost.astype(float) * 0.15, 0, 1)\n",
    "\n",
    "    impressions = rng.integers(50, 20000, size=n)\n",
    "    device      = rng.choice([\"mobile\", \"desktop\"], size=n, p=[0.7, 0.3])\n",
    "    hour        = rng.integers(0, 24, size=n)\n",
    "\n",
    "    competition = rng.uniform(0.1, 1.0, size=n)\n",
    "    cpc = np.clip(\n",
    "        0.2 + 2.0 * competition + 0.5 * (1 - similarity) + rng.normal(0, 0.15, size=n),\n",
    "        0.05, None\n",
    "    )\n",
    "\n",
    "    device_boost = np.where(device == \"mobile\", 0.02, 0.0)\n",
    "    hour_boost   = np.where((hour >= 19) & (hour <= 23), 0.01, 0.0)\n",
    "    ctr = np.clip(\n",
    "        0.01 + 0.10 * similarity + device_boost + hour_boost + rng.normal(0, 0.01, size=n),\n",
    "        0.0005, 0.30\n",
    "    )\n",
    "\n",
    "    clicks = rng.binomial(impressions, p=ctr)\n",
    "    cost   = clicks * cpc\n",
    "\n",
    "    conv_p = 1 / (1 + np.exp(-(-2.0 + 4.0 * similarity - 0.4 * cpc)))\n",
    "    conversions    = rng.binomial(np.maximum(clicks, 1), p=np.clip(conv_p, 0.0001, 0.8))\n",
    "    has_conversion = (conversions > 0).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"given_word\":     given,\n",
    "        \"keyword\":        kw,\n",
    "        \"similarity\":     similarity,\n",
    "        \"competition\":    competition,\n",
    "        \"impressions\":    impressions,\n",
    "        \"clicks\":         clicks,\n",
    "        \"cpc\":            cpc,\n",
    "        \"cost\":           cost,\n",
    "        \"device\":         device,\n",
    "        \"hour\":           hour,\n",
    "        \"ctr\":            np.where(impressions > 0, clicks / impressions, 0.0),\n",
    "        \"has_conversion\": has_conversion,\n",
    "        \"conversions\":    conversions,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "df = make_ads_dataset(8000)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Prepare features\n",
    "\n",
    "LightGBM handles categorical features natively when they are `pandas.Categorical` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "FEATURE_COLS = [\n",
    "    \"given_word\", \"keyword\", \"similarity\", \"competition\",\n",
    "    \"impressions\", \"clicks\", \"cpc\", \"cost\", \"device\", \"hour\"\n",
    "]\n",
    "CAT_COLS = [\"given_word\", \"keyword\", \"device\"]\n",
    "\n",
    "X = df[FEATURE_COLS].copy()\n",
    "for c in CAT_COLS:\n",
    "    X[c] = X[c].astype(\"category\")\n",
    "\n",
    "y_ctr  = df[\"ctr\"].values\n",
    "y_conv = df[\"has_conversion\"].values\n",
    "\n",
    "X_train, X_test, y_ctr_train, y_ctr_test = train_test_split(\n",
    "    X, y_ctr, test_size=0.2, random_state=42\n",
    ")\n",
    "# reuse the same split indices for the conversion target\n",
    "y_conv_train = y_conv[X_train.index]\n",
    "y_conv_test  = y_conv[X_test.index]\n",
    "\n",
    "print(f\"Train: {X_train.shape}  |  Test: {X_test.shape}\")\n",
    "print(f\"Conversion rate (train): {y_conv_train.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model A — CTR prediction (regression)\n",
    "\n",
    "CTR is continuous and bounded in (0, 1). We weight each sample by `impressions` so high-volume rows have more influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "reg = lgb.LGBMRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "reg.fit(\n",
    "    X_train, y_ctr_train,\n",
    "    sample_weight=X_train[\"impressions\"],\n",
    "    eval_set=[(X_test, y_ctr_test)],\n",
    "    eval_sample_weight=[X_test[\"impressions\"]],\n",
    "    eval_metric=\"l2\",\n",
    "    categorical_feature=CAT_COLS,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False),\n",
    "               lgb.log_evaluation(period=200)],\n",
    ")\n",
    "\n",
    "pred_ctr = reg.predict(X_test)\n",
    "rmse = mean_squared_error(y_ctr_test, pred_ctr, squared=False)\n",
    "print(f\"\\nCTR RMSE : {rmse:.6f}\")\n",
    "print(f\"Best iter: {reg.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Model B — Conversion prediction (binary classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train, y_conv_train,\n",
    "    eval_set=[(X_test, y_conv_test)],\n",
    "    eval_metric=\"auc\",\n",
    "    categorical_feature=CAT_COLS,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False),\n",
    "               lgb.log_evaluation(period=200)],\n",
    ")\n",
    "\n",
    "proba = clf.predict_proba(X_test)[:, 1]\n",
    "print(f\"\\nAUC   : {roc_auc_score(y_conv_test, proba):.4f}\")\n",
    "print(f\"PR-AUC: {average_precision_score(y_conv_test, proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Rank keywords for a given word\n",
    "\n",
    "For a new `given_word`, score a list of candidate keywords using:\n",
    "- `pred_ctr` from the regression model\n",
    "- `pred_conv_prob` from the classifier\n",
    "- `score = pred_ctr × pred_conv_prob` (customize to ROAS, profit, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_keywords_for_given(given_word: str, candidates: list[str], base_features: dict) -> pd.DataFrame:\n",
    "    \"\"\"Score and rank candidate keywords for a given word.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    given_word   : The query / seed word.\n",
    "    candidates   : List of keyword strings to evaluate.\n",
    "    base_features: Dict with values for all feature columns except\n",
    "                   given_word and keyword.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame sorted by score descending.\n",
    "    \"\"\"\n",
    "    rows = [\n",
    "        {**base_features, \"given_word\": given_word, \"keyword\": kw}\n",
    "        for kw in candidates\n",
    "    ]\n",
    "    Xcand = pd.DataFrame(rows)[FEATURE_COLS]\n",
    "    for c in CAT_COLS:\n",
    "        Xcand[c] = Xcand[c].astype(\"category\")\n",
    "\n",
    "    ctr_hat  = reg.predict(Xcand)\n",
    "    conv_hat = clf.predict_proba(Xcand)[:, 1]\n",
    "\n",
    "    out = pd.DataFrame({\n",
    "        \"given_word\":     given_word,\n",
    "        \"keyword\":        candidates,\n",
    "        \"pred_ctr\":       ctr_hat,\n",
    "        \"pred_conv_prob\": conv_hat,\n",
    "        \"score\":          ctr_hat * conv_hat,   # ← swap for ROAS/profit\n",
    "    })\n",
    "    return out.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "candidates = [\"refinance\", \"mortgage\", \"card\", \"booking\",\n",
    "              \"ticket\", \"policy\", \"espresso\", \"dslr\"]\n",
    "\n",
    "base = {\n",
    "    \"similarity\":  0.7,\n",
    "    \"competition\": 0.6,\n",
    "    \"impressions\": 5000,\n",
    "    \"clicks\":      0,     # planning mode — no historic clicks yet\n",
    "    \"cpc\":         2.0,\n",
    "    \"cost\":        0.0,\n",
    "    \"device\":      \"mobile\",\n",
    "    \"hour\":        21,\n",
    "}\n",
    "\n",
    "ranked = rank_keywords_for_given(\"loan\", candidates, base)\n",
    "ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Learning-to-Rank with LambdaMART\n",
    "\n",
    "A proper LambdaMART setup requires:\n",
    "1. **Group-based train/test split** — keep all rows for a `given_word` in the same split.\n",
    "2. **Group sizes array** — number of candidate keywords per query, in order.\n",
    "3. **Relevance labels** — here we use `ctr`; in production use ROAS or conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRanker\n",
    "\n",
    "# ── 6a) Group-based train/test split ──────────────────────────────────────────\n",
    "unique_given = df[\"given_word\"].unique()\n",
    "rng_split    = np.random.default_rng(0)\n",
    "rng_split.shuffle(unique_given)\n",
    "\n",
    "split_idx    = int(len(unique_given) * 0.8)\n",
    "train_words  = set(unique_given[:split_idx])\n",
    "test_words   = set(unique_given[split_idx:])\n",
    "\n",
    "df_rank = df.sort_values(\"given_word\").copy()\n",
    "\n",
    "mask_train = df_rank[\"given_word\"].isin(train_words)\n",
    "df_r_train = df_rank[mask_train].copy()\n",
    "df_r_test  = df_rank[~mask_train].copy()\n",
    "\n",
    "print(f\"Ranker train rows: {len(df_r_train)}  |  test rows: {len(df_r_test)}\")\n",
    "print(f\"Train given_words: {sorted(train_words)}\")\n",
    "print(f\"Test  given_words: {sorted(test_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 6b) Build feature matrices and group size arrays ──────────────────────────\n",
    "def build_rank_arrays(subset: pd.DataFrame):\n",
    "    Xr = subset[FEATURE_COLS].copy()\n",
    "    for c in CAT_COLS:\n",
    "        Xr[c] = Xr[c].astype(\"category\")\n",
    "    y  = subset[\"ctr\"].values\n",
    "    groups = subset.groupby(\"given_word\", sort=True).size().tolist()\n",
    "    return Xr, y, groups\n",
    "\n",
    "Xr_train, yr_train, groups_train = build_rank_arrays(df_r_train)\n",
    "Xr_test,  yr_test,  groups_test  = build_rank_arrays(df_r_test)\n",
    "\n",
    "print(f\"Group sizes (train): {groups_train}\")\n",
    "print(f\"Group sizes (test) : {groups_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 6c) Train LambdaMART ranker ───────────────────────────────────────────────\n",
    "ranker = LGBMRanker(\n",
    "    objective=\"lambdarank\",\n",
    "    metric=\"ndcg\",\n",
    "    ndcg_eval_at=[3, 5, 10],\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=63,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "ranker.fit(\n",
    "    Xr_train, yr_train,\n",
    "    group=groups_train,\n",
    "    eval_set=[(Xr_test, yr_test)],\n",
    "    eval_group=[groups_test],\n",
    "    categorical_feature=CAT_COLS,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False),\n",
    "               lgb.log_evaluation(period=200)],\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration: {ranker.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── 6d) Inspect ranker scores for one test given_word ─────────────────────────\n",
    "sample_word = list(test_words)[0]\n",
    "df_sample   = df_r_test[df_r_test[\"given_word\"] == sample_word].copy()\n",
    "\n",
    "Xs = df_sample[FEATURE_COLS].copy()\n",
    "for c in CAT_COLS:\n",
    "    Xs[c] = Xs[c].astype(\"category\")\n",
    "\n",
    "df_sample[\"ranker_score\"] = ranker.predict(Xs)\n",
    "df_sample[[\"given_word\", \"keyword\", \"ctr\", \"ranker_score\"]] \\\n",
    "    .sort_values(\"ranker_score\", ascending=False) \\\n",
    "    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Feature importance\n",
    "\n",
    "Using **gain** (total reduction in loss attributed to each feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_importance(model, title: str):\n",
    "    fi = pd.DataFrame({\n",
    "        \"feature\":    model.feature_name_,\n",
    "        \"importance\": model.booster_.feature_importance(importance_type=\"gain\"),\n",
    "    }).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    print(fi.to_string(index=False))\n",
    "    return fi\n",
    "\n",
    "fi_reg    = show_importance(reg,    \"CTR Regression\")\n",
    "fi_clf    = show_importance(clf,    \"Conversion Classifier\")\n",
    "fi_ranker = show_importance(ranker, \"LambdaMART Ranker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick-reference: choosing the right setup\n",
    "\n",
    "| Success metric | Target variable | LightGBM objective | Eval metric |\n",
    "|---|---|---|---|\n",
    "| CTR | `ctr` (float) | `regression` | RMSE / MAE |\n",
    "| Conversion | `has_conversion` (0/1) | `binary` | AUC / PR-AUC |\n",
    "| ROAS / Profit | continuous value | `regression` or `tweedie` | RMSE |\n",
    "| Click volume | `clicks` (count) | `poisson` | — |\n",
    "| Keyword ranking | any relevance label | `lambdarank` | NDCG@k |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
